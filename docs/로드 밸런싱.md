---
title: 로드 밸런싱
aliases: ["load balancing", "alb", "nlb", "elb", "로드밸런서", "부하분산"]
---

# 로드 밸런싱

> 트래픽을 여러 서버로 분산하는 방식

들어오는 요청을 여러 서버에 나눠서 보내는 방식이다. 마트 계산대가 여러 개면 손님이 분산되는 것과 같다. 한 서버에 부하가 몰리는 걸 방지한다.

## 동작 원리

클라이언트는 로드 밸런서 주소로 요청한다. 로드 밸런서가 뒤에 있는 여러 서버 중 하나를 선택해서 전달한다. 서버가 응답하면 다시 클라이언트로 전달.

**분산 알고리즘**:

- Round Robin - 순서대로 돌아가면서
- Least Connections - 연결 적은 서버로
- IP Hash - 같은 IP는 같은 서버로 (세션 유지)
- Weighted - 가중치에 따라 분배

## 용도

웹 서버 여러 대 앞에 두고 트래픽 분산. API 서버 스케일아웃 시 필수. [[마이크로서비스]] 간 통신에서도 사용.

## 장단점

**장점**: [[확장성]] 확보, [[가용성]] 향상 (한 대 죽어도 다른 서버가 처리), 유지보수 중 서비스 유지

**단점**: 추가 홉으로 약간의 지연, 세션 관리 복잡해짐, 장애 포인트 추가

## 주의점

**Health Check 필수**: 죽은 서버로 요청 보내면 안 됨. 주기적 헬스체크로 살아있는 서버만 풀에 유지.

**Sticky Session**: 세션 기반 애플리케이션은 같은 사용자를 같은 서버로 보내야 할 수 있음.

## 생태계

- [[Nginx]] - L7 로드 밸런서
- [[HAProxy]] - 고성능 로드 밸런서
- [[AWS ALB/NLB]] - 클라우드 매니지드
- [[Kubernetes Service]] - 클러스터 내 로드밸런싱

## 기타

로드 밸런서는 사실 오래된 개념이다. 1990년대 인터넷 붐 때부터 있었다. 당시엔 하드웨어 장비였고 엄청 비쌌다. F5 Networks 같은 회사가 전문으로 만들었다. 요즘은 소프트웨어 로드 밸런서([[Nginx]], [[HAProxy]])가 주류다.

"L4 vs L7" 로드 밸런싱 구분이 있다. L4는 IP, 포트 기준으로 분산하고, L7은 HTTP 헤더, URL 같은 애플리케이션 레벨에서 분산한다. L7이 더 똑똑하지만 오버헤드가 있다. 용도에 맞게 선택해야 한다.

"로드 밸런서가 단일 장애점(SPOF)"이 될 수 있다. 로드 밸런서가 죽으면 뒤의 서버가 멀쩡해도 서비스가 마비된다. 그래서 로드 밸런서도 이중화한다. Active-Standby 구성으로 하나 죽으면 다른 게 받는 식.

클라우드 시대에는 로드 밸런서 설정이 훨씬 쉬워졌다. AWS ALB는 웹 콘솔에서 몇 번 클릭하면 된다. 오토 스케일링과 연동하면 트래픽에 따라 서버가 자동으로 늘었다 줄었다 한다. 예전엔 상상도 못 할 일이었다.

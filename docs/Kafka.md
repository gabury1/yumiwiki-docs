---
title: Kafka
aliases: ["kafka", "apache kafka", "카프카", "메시지큐"]
---

# Kafka

> 대용량 실시간 데이터 스트리밍이 필요할 때

[[분산 스트리밍 플랫폼]]이다. LinkedIn에서 만들었고 2011년 오픈소스화. [[Apache]] 재단 프로젝트. 초당 수백만 건의 메시지를 처리할 수 있다.

메시지 큐처럼 쓸 수 있지만, 단순 큐보다 훨씬 강력하다. 메시지를 디스크에 저장하고, 여러 컨슈머가 같은 메시지를 읽을 수 있다. 메시지 유실 없이 재처리도 가능.

[[마이크로서비스]] 간 통신, 로그 수집, 실시간 분석 파이프라인, 이벤트 소싱 아키텍처에 쓴다. Netflix, Uber, LinkedIn, 카카오 다 Kafka 쓴다.

[[RabbitMQ]]보다 복잡하지만 더 강력하다. 처리량이 중요하면 Kafka, 단순하고 다양한 프로토콜 필요하면 [[RabbitMQ]].

## 성능

처리량이 핵심 강점이다. 초당 수십만~수백만 메시지 가능. 디스크에 순차 쓰기해서 오히려 빠르다. 배치로 묶어서 네트워크 효율도 좋다.

파티션으로 병렬 처리. 토픽을 여러 파티션으로 나누고, 파티션마다 다른 컨슈머가 처리. 파티션 늘리면 처리량도 늘어난다.

디스크 기반이라 메모리보다 저렴하게 대용량 저장 가능. 보존 기간 설정해서 며칠~몇 주치 메시지 보관. 과거 데이터 다시 읽기(replay) 가능.

ZooKeeper가 필요했는데, Kafka 3.x부터 KRaft 모드로 ZooKeeper 없이도 된다.

## 생태계

[[Kafka Connect]]로 외부 시스템 연동. DB CDC, S3, Elasticsearch 등 수백 개 커넥터가 있다. 코드 없이 데이터 파이프라인 구축 가능.

[[Kafka Streams]]로 스트림 처리 애플리케이션 개발. [[Apache Flink]], [[Spark Streaming]]과 연동도 가능. 실시간 집계, 필터링, 조인 가능.

[[Schema Registry]]로 메시지 스키마 관리. [[Avro]], [[Protobuf]] 포맷 쓰면 타입 안전하게 통신.

매니지드: [[Confluent Cloud]], [[Amazon MSK]], [[Aiven]]. 직접 운영하면 복잡하니까 프로덕션에서는 매니지드 추천.

클라이언트 라이브러리: [[librdkafka]] 기반으로 모든 언어 지원. [[Java]]는 공식 클라이언트, [[Python]]은 [[confluent-kafka-python]].

## 주의점

**운영 복잡도**: ZooKeeper(또는 KRaft), Broker, Connect, Schema Registry 다 띄워야 한다. 클러스터 관리, 파티션 리밸런싱, 디스크 용량 관리 필요. 매니지드 서비스 쓰는 게 정신 건강에 좋다.

**파티션 설계 중요**: 파티션 키에 따라 메시지가 분산된다. 키가 편중되면 핫 파티션 발생. 한 번 늘린 파티션은 줄일 수 없다. 초기 설계 신중하게.

**컨슈머 그룹 이해**: 같은 그룹의 컨슈머는 파티션을 나눠 가진다. 컨슈머 수가 파티션 수보다 많으면 놀게 된다. 리밸런싱 중에는 일시 중단.

**순서 보장 범위**: 전체 토픽이 아니라 파티션 내에서만 순서 보장. 전역 순서 필요하면 파티션 1개 써야 하는데 그러면 처리량 포기.

**정확히 한 번(Exactly-once)**: 가능하긴 한데 설정 복잡하고 성능 오버헤드 있다. idempotent producer, transactional API 써야 함. 대부분은 at-least-once로 충분.

**컨슈머 랙 모니터링**: 컨슈머가 프로듀서를 못 따라가면 랙이 쌓인다. 모니터링해서 컨슈머 스케일아웃하거나 처리 로직 최적화.

**디스크 공간**: 보존 기간 동안 메시지 쌓이니까 디스크 계획 잘 세워야 한다. retention.bytes, retention.ms 설정.

## 주요 기능

- 고처리량 분산 메시징
- 파티셔닝과 병렬 처리
- 메시지 영속성 (디스크 저장)
- 컨슈머 그룹 (부하 분산)
- 메시지 재처리 (offset 조절)
- Kafka Connect (데이터 통합)
- Kafka Streams (스트림 처리)
- 정확히 한 번 전달 (Exactly-once semantics)

## 기타

LinkedIn 엔지니어들이 내부 데이터 파이프라인 문제를 해결하려고 만들었다. 2011년 오픈소스화했고, 2012년 [[Apache]] 재단 프로젝트가 됐다. 이름은 작가 프란츠 카프카에서 따왔다. "작가가 글을 쓰듯 시스템이 로그를 쓴다"는 의미라고.

Kafka 창시자 Jay Kreps는 LinkedIn 떠나서 Confluent라는 회사를 차렸다. Kafka 상용 버전과 매니지드 서비스를 판다. 오픈소스 Kafka는 Apache 라이센스지만, Confluent 추가 기능들은 상용이다. 전형적인 오픈코어 비즈니스 모델.

"Kafka는 데이터베이스다"라는 주장이 있다. 메시지를 디스크에 영구 저장하고, 재처리할 수 있으니 일종의 이벤트 저장소로 볼 수 있다. [[이벤트 소싱]] 아키텍처의 핵심 인프라가 Kafka다.

Netflix는 하루에 Kafka로 7조 개 이상의 메시지를 처리한다고 밝혔다. LinkedIn, Uber, Spotify, Airbnb 등 대형 서비스들이 Kafka를 쓴다. "빅테크 기업의 데이터 인프라 = Kafka"라는 공식이 어느 정도 성립한다.
